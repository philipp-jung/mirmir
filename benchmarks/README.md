# Benchmarks
An important part of the Mimir paper is its extensive benchmark with existing cleaning solutions.
Directories at this file's location contain utilities that help create benchmarks for each method Mimir is compared to.

## GARF
We ported GARF to sqlite3. Originally, GARF uses an Oracle database, which we are not licensed to work with.
For each to-be-cleaned table, the following three tables need to exist in the database:
- `table_name`, which contains the ground truth.
- `table_name_dirty`, which contains the dirty data.
- `table_name_copy`, which contains the dirty data, again. This table will be iteratively cleaned by GARF.

A sqlite database with the corresponding structure named `to_garf.db` can be generated by navigating into the `benchmarks/garf` directory, and executing `python export_to_garf.py` there.

You find detailed instructions on how to run GARF to measure a baseline in the `garf/` directory.

## HoloClean
HoloClean uses Denial Constraints (DCs) to detect and clean data.
Generally, DCs are not available for a given dataset.
They can be mined however.
To mine them, we use the Hydra algorithm, which finds all DCs on a dataset.
We use [Metanome](http://metanome.de) to run Hydra.
Information on how to use Hydra can be found on the Metanome website.

### Mining DCs
Navigate to the holoclean directory.
There, run `python export_metanome_input.py` to export ground truth to `to_metanome/`.

In Metanome, add these datasets.
Doing so, make sure you indicate that the first row contains header information.
Other settings are standard.

Metanome outputs results of mining DCs in the `results/` directory.
Copy files in that directory over to `metanome_output/`.

### Exporting data to Holoclean
Once the Metanome outputs are stored in the `metanome_output/` directory, run `python export_holoclean_input.py`.
This will store clean and dirty versions of datasets in `holoclean_input/datasets/`, and converted DCs in `holoclean_input/dcs/`.
Files in datasets without a `_` in their name are the ground truth versions.
The format for dirty datasets is `{dataset_name}_{error_fraction}_{version}.csv`, with the exception of the Baran datasets.
These are simply called `{dataset_name}_dirty.csv`

Holoclean expects the ground truth in a funky format, with the first column being the row number (int), the second column being the attribute name (str), and the third column being the value.
The ground truth files are converted accordingly by `export_holoclean_input.py`.
